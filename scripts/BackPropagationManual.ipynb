{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt #Para graficar\n",
    "from skimage.io import imshow #Para graficar las imagenes\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "##from PIL import Image\n",
    "import cv2\n",
    "\n",
    "#import pyheif\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = \"C:/MaestriaDocs/DMA - Proyecto/caras_grupo4/\"\n",
    "root_path = \"../\"\n",
    "\n",
    "directorio_personas = root_path + \"Caras_cortadas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos de las carpetas originales las fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta: Abel\n",
      "Carpeta: Carlos\n",
      "Carpeta: Federico G\n",
      "Carpeta: Federico R\n",
      "Carpeta: Florencia\n",
      "Carpeta: Franco A\n",
      "Carpeta: Franco S\n",
      "Carpeta: Gerard\n",
      "Carpeta: Gustavo\n",
      "Carpeta: Joaquin\n",
      "Carpeta: Juan\n",
      "Carpeta: Lautaro\n",
      "Carpeta: Lisandro\n",
      "Carpeta: Marco\n",
      "Carpeta: Matias\n",
      "Carpeta: Natalia\n",
      "Carpeta: Noelia\n",
      "Carpeta: Paola\n",
      "Carpeta: Victorio\n"
     ]
    }
   ],
   "source": [
    "from PCA_funciones import matriz_fotos_desde_carpeta\n",
    "\n",
    "image_matrix, image_person = matriz_fotos_desde_carpeta(directorio_personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicamos Backpropagation\n",
    "Transformamos las imagenes, con la cantidad de copoenentes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.22160860e+00 -7.80849051e+00 -2.07612021e-01 ... -7.16897218e-01\n",
      "  -2.28025618e-01 -3.38966655e-01]\n",
      " [-7.84286624e+00 -1.12024841e+01  4.89598300e-01 ... -7.43509551e-01\n",
      "  -6.18654161e-01  2.88035939e-01]\n",
      " [-6.55630242e+00 -7.80088794e+00 -1.49179444e+00 ... -1.37140978e+00\n",
      "  -2.96450608e-01  2.05965925e-02]\n",
      " ...\n",
      " [ 3.55657307e+00  6.49301206e-01 -6.23891347e+00 ... -6.32500626e-02\n",
      "   3.18870940e-01 -6.26304974e-01]\n",
      " [-2.65755973e+00 -4.44534213e-03 -8.82886566e+00 ...  2.92722209e-01\n",
      "  -9.78650328e-02 -2.65089331e-01]\n",
      " [-2.62864833e+00  8.66772857e-01 -8.11920552e+00 ...  1.20877517e-01\n",
      "  -1.40180893e-02 -1.42284246e-01]]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "\n",
    "# Cargar los componentes PCA guardados\n",
    "ruta_pca = root_path + \"PCA/Componentes_pca.npy\" #lo tenemos en memoria pero lo leemos nuevamente por si separamos el codigo\n",
    "pca_components = np.load(ruta_pca)\n",
    "\n",
    "# Cargar el escalador\n",
    "ruta_scaler = root_path + 'PCA/scaler.pkl' #\n",
    "with open(ruta_scaler, 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Función para transformar una imagen con un rango específico de componentes PCA\n",
    "def transformar_imagen_pca(imagen, scaler, pca_components, num_componentes=50, inicio_componente=0):\n",
    "    # Estandarizar la imagen\n",
    "    imagen_estandarizada = scaler.transform(imagen)\n",
    "    \n",
    "    # Seleccionar el rango de componentes\n",
    "    componentes_seleccionados = pca_components[inicio_componente:inicio_componente + num_componentes]\n",
    "    \n",
    "    # Realizar la proyección manualmente\n",
    "    imagen_pca = np.dot(imagen_estandarizada, componentes_seleccionados.T)\n",
    "    return imagen_pca\n",
    "\n",
    "\n",
    "# Especificar la cantidad de componentes a utilizar y el componente de inicio\n",
    "num_componentes = 60\n",
    "inicio_componente = 2 #inicia a partir de la 3ta componente\n",
    "\n",
    "# Transformar la nueva imagen utilizando los componentes especificados\n",
    "imagenes_pca_reducidas = transformar_imagen_pca( image_matrix, scaler, pca_components, num_componentes, inicio_componente)\n",
    "\n",
    "print(imagenes_pca_reducidas)\n",
    "\n",
    "imagenes_pca_reducidas.shape\n",
    "personas = np.unique(image_person)\n",
    "image_person #(vector que tiene el nombre de la persona de cada foto)\n",
    "personas\n",
    "personas.shape\n",
    "cantidad_personas = len(personas)\n",
    "print(cantidad_personas) \n",
    "cantidad_fotos = len(image_person)\n",
    "cantidad_fotos\n",
    "# salida_lista = []  # Array vacío para almacenar las listas de 0 y 1\n",
    "# cantidad_personas = len(personas) #podiramos hacer un elemento menos pero por ahora lo dejamos en el total\n",
    "# # Recorrer cada elemento en \"image_person\"\n",
    "# for imagen_persona in image_person:\n",
    "#   lista_persona = [0] * cantidad_personas   # Inicializar lista con 18 ceros\n",
    "  \n",
    "#   # Buscar el índice del nombre de la imagen en \"personas\"\n",
    "#  # Encontrar el índice de la persona\n",
    "#   indice_persona =  np.where(personas == imagen_persona)[0]\n",
    "\n",
    "#   # Si se encuentra la persona, actualizar la lista\n",
    "#   if len(indice_persona) > 0:\n",
    "#     lista_persona[indice_persona[0]] = 1\n",
    "  \n",
    "#   # Actualizar el elemento correspondiente en la lista con 1\n",
    "\n",
    "  \n",
    "#   # Agregar la lista a Y\n",
    "#   salida_lista.append(lista_persona)\n",
    "\n",
    "# salida_lista = np.array(salida_lista) \n",
    "# salida_lista\n",
    "\n",
    "imagenes_pca_reducidas[0]\n",
    "X=imagenes_pca_reducidas\n",
    "X.shape\n",
    "from sklearn.preprocessing import  LabelBinarizer\n",
    "# Convertir los valores de la var categórica en números\n",
    "#salida_lista = LabelBinarizer().fit_transform(image_person) #convierte los nombres (var categorica) en vextores con un 1 en la posicion del nombre\n",
    "#correspondiente, tiene un renglon por foto y el vector una columna por nombre solo un 1 en el nombre de la persona de la foto\n",
    "\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "salida_lista = label_binarizer.fit_transform(image_person)\n",
    "salida_lista\n",
    "salida_lista.shape\n",
    "X = imagenes_pca_reducidas\n",
    "Y = salida_lista\n",
    "\n",
    "# Normalización de las entradas\n",
    "\"\"\"mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "X = (X - mean) / std\n",
    "\"\"\"\n",
    "# Convierte la lista a un arreglo NumPy\n",
    "#salida_lista = nombres_personas\n",
    "salida = np.array(salida_lista)\n",
    "Y = salida #salida.reshape(len(X),1)\n",
    "\n",
    "epoch_limit = 30\n",
    "\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(1021) #Establece la semilla para las funciones aleatorias de numpy.  \n",
    "tf.random.set_seed(1021) #Establece la semilla para las funciones aleatorias de TensorFlow, asegurando que los pesos iniciales de la red neuronal y 4cualquier otra operación aleatoria en TensorFlow sean reproducibles.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUEVO # ------------------------------------------\n",
    "\n",
    "# backpropagation, just one hidden layer\n",
    "# lo hago con  matrices de pesos\n",
    "# puedo tener tantos inputs como quiera\n",
    "# puedo tener tantas neuronas ocultas como quiera\n",
    "# puedo tener tanas neuronas de salida como quiera\n",
    "# fuera de este codigo esta la decision que tomo segun el valor de salida de cada neurona de salida\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.preprocessing import standardize\n",
    "\n",
    "#from graficos import perceptron_plot \n",
    "\n",
    "def func_eval(fname, x):\n",
    "    match fname:\n",
    "        case \"purelin\":\n",
    "            y = x\n",
    "        case \"logsig\":\n",
    "            y = 1.0 / ( 1.0 + math.exp(-x) )\n",
    "        case \"tansig\":\n",
    "            y = 2.0 / ( 1.0 + math.exp(-2.0*x) ) - 1.0\n",
    "    return y\n",
    "\n",
    "func_eval_vec = np.vectorize(func_eval)\n",
    "\n",
    "def deriv_eval(fname, y):  #atencion que y es la entrada y=f( x )\n",
    "    match fname:\n",
    "        case \"purelin\":\n",
    "            d = 1.0\n",
    "        case \"logsig\":\n",
    "            d = y*(1.0-y)\n",
    "        case \"tansig\":\n",
    "            d = 1.0 - y*y\n",
    "    return d\n",
    "\n",
    "deriv_eval_vec = np.vectorize(deriv_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1206"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_faces_array_transformed.shape #vemos el vector con las caras y sus 60 componentes a partir de la 3ra\n",
    "\n",
    "# Normalización de las entradas\n",
    "#mean = np.mean(X, axis=0)\n",
    "#std = np.std(X, axis=0)\n",
    "#X = (X - mean) / std\n",
    "\n",
    "# Convierte la lista a un arreglo NumPy\n",
    "#salida_lista = nombres_personas\n",
    "#salida = np.array(salida_lista)\n",
    "#Y = salida #salida.reshape(len(X),1)\n",
    "\n",
    "filas_qty = len(X)        #la cantidad de fotos\n",
    "input_size = X.shape[1]   #  entradas la cantidad de componentes\n",
    "                            # hidden_size = 3  # neuronas capa oculta\n",
    "hidden_size1 = filas_qty       # 8  Neuronas en la primera capa oculta, para el 8 teniamos 8 recuadros, aca por ahora ponemos la cantidad de fotos \n",
    "hidden_size2 = 3               # Neuronas en la segunda capa oculta\n",
    "#output_size = Y.shape[2]  # 2 neurona\n",
    "output_size = cantidad_personas #VEER , vector con la probabilidad q sea la persona de la posicion\n",
    "\n",
    "# defino las funciones de activacion de cada capa\n",
    "hidden_FUNC = 'logsig'  # uso la logistica\n",
    "output_FUNC = 'tansig'  # uso la tangente hiperbolica\n",
    "\n",
    "# Incializo las matrices de pesos azarosamente\n",
    "# W1 son los pesos que van del input a la capa oculta\n",
    "# W2 son los pesos que van de la capa oculta a la capa de salida\n",
    "np.random.seed(1021) #mi querida random seed para que las corridas sean reproducibles\n",
    "W1 = np.random.uniform(-0.5, 0.5, [hidden_size1, input_size])\n",
    "X01 = np.random.uniform(-0.5, 0.5, [hidden_size1, 1] )\n",
    "W2 = np.random.uniform(-0.5, 0.5, [hidden_size2, hidden_size1])\n",
    "X02 = np.random.uniform(-0.5, 0.5, [hidden_size2, 1] )\n",
    "W3 = np.random.uniform(-0.5, 0.5, [output_size, hidden_size2])\n",
    "X03 = np.random.uniform(-0.5, 0.5, [output_size, 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09530823210793035"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Avanzo la red, forward\n",
    "# # para TODOS los X al mismo tiempo ! \n",
    "# #  @ hace el producto de una matrix por un vector_columna\n",
    "# hidden_estimulos = W1 @ X.T + X01\n",
    "# hidden_salidas = func_eval_vec(hidden_FUNC, hidden_estimulos)\n",
    "# output_estimulos = W2 @ hidden_salidas + X02\n",
    "# output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
    "\n",
    "\n",
    "# Función de propagación hacia adelante (forward propagation)\n",
    "def forward_propagation(X, W1, b1, W2, b2, W3, b3):\n",
    "    hidden1_estimulos = W1 @ X.T + b1\n",
    "    hidden1_salidas = func_eval_vec(hidden_FUNC, hidden1_estimulos)\n",
    "    hidden2_estimulos = W2 @ hidden1_salidas + b2\n",
    "    hidden2_salidas = func_eval_vec(hidden_FUNC, hidden2_estimulos)\n",
    "    output_estimulos = W3 @ hidden2_salidas + b3\n",
    "    output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
    "    return hidden1_salidas, hidden2_salidas, output_salidas, hidden1_estimulos, hidden2_estimulos, output_estimulos\n",
    "\n",
    "\n",
    "hidden_salida1, hidden_salida2, output_salidas, _, _ ,_ = forward_propagation(X, W1, X01, W2, X02, W3, X03)\n",
    "\n",
    "\n",
    "# calculo el error promedi general de TODOS los X\n",
    "Error= np.mean( (Y.T - output_salidas)**2 )\n",
    "\n",
    "# Inicializo\n",
    "#epoch_limit = 5000    # para terminar si no converge\n",
    "Error_umbral = 1.0e-06\n",
    "#Error_umbral = 1.0e-15\n",
    "learning_rate = 0.5\n",
    "#learning_rate = 0.2\n",
    "Error_last = 10    # lo debo poner algo dist a 0 la primera vez\n",
    "epoch = 0\n",
    "\n",
    "while ( math.fabs(Error_last-Error)>Error_umbral and (epoch < epoch_limit)):\n",
    "    epoch += 1\n",
    "    Error_last = Error\n",
    "\n",
    "    # recorro siempre TODA la entrada\n",
    "    for fila in range(filas_qty): #para cada input x_sub_fila del vector X\n",
    "        # propagar el x hacia adelante\n",
    "        # hidden_estimulos = W1 @ X[fila:fila+1, :].T + X01\n",
    "        # hidden_salidas = func_eval_vec(hidden_FUNC, hidden_estimulos)\n",
    "        # output_estimulos = W2 @ hidden_salidas + X02\n",
    "        # output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
    "        hidden_salida1, hidden_salida2, output_salidas,  _, _ ,_  = forward_propagation(X[fila:fila+1, :], W1, X01, W2, X02, W3, X03)\n",
    "\n",
    "        # calculo los errores en la capa hidden y la capa output\n",
    "        ErrorSalida = Y[fila:fila+1,:].T - output_salidas\n",
    "        # output_delta es un solo numero\n",
    "        output_delta = ErrorSalida * deriv_eval_vec(output_FUNC, output_salidas)\n",
    "        \n",
    "        # hidden_delta es un vector columna\n",
    "        # hidden_delta = deriv_eval_vec(hidden_FUNC, hidden_salidas)*(W2.T @ output_delta)\n",
    "        # hidden_delta es un vector columna\n",
    "        hidden_delta2 = deriv_eval_vec(hidden_FUNC, hidden_salida2)*(W3.T @ output_delta)\n",
    "\n",
    "        # hidden_delta es un vector columna\n",
    "        hidden_delta1 = deriv_eval_vec(hidden_FUNC, hidden_salida1)*(W2.T @ hidden_delta2)\n",
    "\n",
    "        # ya tengo los errores que comete cada capa\n",
    "        # corregir matrices de pesos, voy hacia atras\n",
    "        # backpropagation\n",
    "        W1 = W1 + learning_rate * (hidden_delta1 @ X[fila:fila+1, :] )\n",
    "        X01 = X01 + learning_rate * hidden_delta1\n",
    "        W2 = W2 + learning_rate * (hidden_delta2 @ hidden_salida1.T )\n",
    "        X02 = X02 + learning_rate * hidden_delta2\n",
    "        W3 = W3 + learning_rate * (output_delta @ hidden_salida2.T)\n",
    "        X03 = X03 + learning_rate * output_delta\n",
    "\n",
    "    # ya recalcule las matrices de pesos\n",
    "    # ahora avanzo la red, feed-forward\n",
    "    # hidden_estimulos = W1 @ X.T + X01\n",
    "    # hidden_salidas = func_eval_vec(hidden_FUNC, hidden_estimulos)\n",
    "    # output_estimulos = W2 @ hidden_salidas + X02\n",
    "    # output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
    "    \n",
    "    hidden_salida1, hidden_salida2, output_salidas,  hidden_estimulo1, hidden_estimulo2 , hidden_ouput  = forward_propagation(X[fila:fila+1, :], W1, X01, W2, X02, W3, X03)\n",
    "    \n",
    "\n",
    "    # calculo el error promedio general de TODOS los X\n",
    "    Error= np.mean( (Y.T - output_salidas)**2 )\n",
    "\n",
    "    # tengo que hacer X01.T[0]  para que pase el vector\n",
    "   # grafico.graficarVarias(W1, X01.T[0], epoch, -1)\n",
    "\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "# loss, accuracy = model.evaluate(X_test, y_test)\n",
    "# print(\"Accuracy on test set:\", accuracy)\n",
    "\n",
    "# Hacer predicciones con el modelo entrenado\n",
    "# predictions = model.predict(new_data)\n",
    "Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73194792e-14],\n",
       "       [-1.77635684e-15],\n",
       "       [ 2.66453526e-15],\n",
       "       [ 1.11022302e-15],\n",
       "       [ 2.66453526e-15],\n",
       "       [ 3.77475828e-15],\n",
       "       [ 1.33226763e-15],\n",
       "       [-8.88178420e-16],\n",
       "       [-1.55431223e-15],\n",
       "       [ 3.77475828e-15],\n",
       "       [ 5.77315973e-15],\n",
       "       [-1.11022302e-15],\n",
       "       [-4.21884749e-15],\n",
       "       [ 1.77635684e-15],\n",
       "       [ 2.22044605e-15],\n",
       "       [-2.66453526e-15],\n",
       "       [-4.88498131e-15],\n",
       "       [-8.88178420e-16],\n",
       "       [ 9.55106031e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_salidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuevas Fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Nuevas_Fotos'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_Fotos = root_path + \"Nuevas_Fotos\"\n",
    "p_Fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abel': [],\n",
       " 'Carlos': [],\n",
       " 'Federico G': [],\n",
       " 'Federico R': [],\n",
       " 'Franco S': [],\n",
       " 'Gerard': [],\n",
       " 'Gustavo': [],\n",
       " 'Joaquin': [],\n",
       " 'Lautaro': [],\n",
       " 'Lisandro': [],\n",
       " 'Matias': [],\n",
       " 'Natalia': [],\n",
       " 'Noelia': [],\n",
       " 'Paola': [],\n",
       " 'Victorio': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def Leer_fotos2(directorio_origen_f):\n",
    "\"\"\"\n",
    "    Lee la ruta lee interpretando que cada carpeta es una persona, y dentro de esa careta se encuentran las fotos de esa persona.\n",
    "    Devuelve un diccionario con el nombre de la pesrona como índice y una lista de sus fotos.\n",
    "\"\"\"\n",
    "\n",
    "# Diccionario para almacenar las fotos\n",
    "fotos_int= {} # diccionario interno q sea persona y el vector de fotos, \n",
    "\n",
    "# Recorrer las subcarpetas\n",
    "\n",
    "for nombre_persona in os.listdir(p_Fotos):\n",
    "    # Ruta de la subcarpeta\n",
    "    ruta_persona = os.path.join(p_Fotos, nombre_persona)\n",
    "\n",
    "    # Lista para almacenar las fotos de la persona\n",
    "    fotos_persona = []    \n",
    "    #convertir hiec a png\n",
    "    # convertir_persona_HIEC_a_jpg(ruta_persona)\n",
    "    # Recorrer las fotos de la persona\n",
    "    for archivo in glob.glob(os.path.join(ruta_persona, \"*.jpg\")) :\n",
    "        # Cargar la imagen\n",
    "        imagen = cv2.imread(archivo)              \n",
    "        fotos_persona.append(imagen)             \n",
    "    fotos_int[nombre_persona] = fotos_persona\n",
    "        \n",
    "    #return fotos_int\n",
    "fotos_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abel': [],\n",
       " 'Carlos': [],\n",
       " 'Federico G': [],\n",
       " 'Federico R': [],\n",
       " 'Franco S': [],\n",
       " 'Gerard': [],\n",
       " 'Gustavo': [],\n",
       " 'Joaquin': [],\n",
       " 'Lautaro': [],\n",
       " 'Lisandro': [],\n",
       " 'Matias': [],\n",
       " 'Natalia': [],\n",
       " 'Noelia': [],\n",
       " 'Paola': [],\n",
       " 'Victorio': []}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from Funciones import  Leer_fotos\n",
    "fotos=Leer_fotos2(p_Fotos)\n",
    "fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de personas: 15\n",
      "Cantidad de fotos por persona:\n",
      "- Abel: 0\n",
      "- Carlos: 0\n",
      "- Federico G: 0\n",
      "- Federico R: 0\n",
      "- Franco S: 0\n",
      "- Gerard: 0\n",
      "- Gustavo: 0\n",
      "- Joaquin: 0\n",
      "- Lautaro: 0\n",
      "- Lisandro: 0\n",
      "- Matias: 0\n",
      "- Natalia: 0\n",
      "- Noelia: 0\n",
      "- Paola: 0\n",
      "- Victorio: 0\n"
     ]
    }
   ],
   "source": [
    "# Mostrar información\n",
    "nombres_personas = list(fotos.keys())\n",
    "print(\"Cantidad de personas:\", len(nombres_personas))\n",
    "print(\"Cantidad de fotos por persona:\")\n",
    "for nombre_persona, fotos_persona in fotos.items():\n",
    "    print(f\"- {nombre_persona}: {len(fotos_persona)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recortar_imagen_C(image):\n",
    "    import os\n",
    "    import cv2\n",
    "   # import matplotlib.pyplot as plt\n",
    "    # Convertir la imagen a escala de grises\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Utilizar un clasificador específico para caras\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "    # Detectar rostros en la imagen\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=3, minSize=(30, 30))\n",
    "\n",
    "    # Recorrer las caras detectadas\n",
    "    face_images = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Recortar la cara de la imagen\n",
    "        face_images.append(image[y:y+h, x:x+w])\n",
    "\n",
    "    return face_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'recortar_imagen' from 'Funciones' (c:\\MaestriaDocs\\DMA - Proyecto\\caras_grupo4\\scripts\\Funciones.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFunciones\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m recortar_imagen\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'recortar_imagen' from 'Funciones' (c:\\MaestriaDocs\\DMA - Proyecto\\caras_grupo4\\scripts\\Funciones.py)"
     ]
    }
   ],
   "source": [
    "from Funciones import recortar_imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriz_fotos_nuevas(dir_name):\n",
    "    import os\n",
    "    # Tamaño fijo al que redimensionar todas las imágenes\n",
    "    desired_size = (30, 30)\n",
    "    # Listas para almacenar las imágenes y sus nombres\n",
    "    images = [] #lista de fotos\n",
    "    image_names = []\n",
    "    image_person = [] #lista con los nombres de las personas de cada foto\n",
    "\n",
    "    # Leer las imágenes del directorio y almacenarlas en las listas\n",
    "    images = []\n",
    "    for root, dirs, files in os.walk(dir_name_recorte):\n",
    "        for dir_name in dirs:\n",
    "            print(\"Carpeta:\", dir_name)\n",
    "            dir_path = os.path.join(root, dir_name) #directorio  de la persona\n",
    "\n",
    "            for file_name in os.listdir(dir_path):\n",
    "\n",
    "                if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                    image_path = os.path.join(dir_path, file_name)\n",
    "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Leer en escala de grises\n",
    "                if image is not None:\n",
    "                    # Redimensionar la imagen al tamaño deseado\n",
    "                    resized_image = cv2.resize(image, desired_size)\n",
    "\n",
    "                    images.append(resized_image.flatten())  # Aplanar la imagen y agregarla a la lista\n",
    "                    image_names.append(file_name)\n",
    "                    image_person.append(dir_name)\n",
    "\n",
    "    # Convertir la lista de imágenes a una matriz NumPy\n",
    "    image_matrix = np.array(images) #matriz de fotos    \n",
    "    return image_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 43-44: malformed \\N character escape (1492511354.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    p_Foto =\"C:\\MaestriaDocs\\DMA - Proyecto\\caras_grupo4\\Nuevas_fotos\\Abel.jpeg\"\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 43-44: malformed \\N character escape\n"
     ]
    }
   ],
   "source": [
    "p_Foto =\"C:\\MaestriaDocs\\DMA - Proyecto\\caras_grupo4\\Nuevas_fotos\\Abel.jpeg\"\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "#from Funciones import recortar_imagen\n",
    "# Cargar la imagen nueva\n",
    "\n",
    "\n",
    "nueva_imagen = cv.imread(p_Foto)\n",
    "if nueva_imagen is None:\n",
    "    print (\"no se pudo cargar la imagen\")\n",
    "else:\n",
    "    #uso el proceso de guardar la imagen recortada\n",
    "    face_images = recortar_imagen_C(nueva_imagen)\n",
    "    # images.extend(face_images)\n",
    "\n",
    "    for face_image in face_images:\n",
    "        nueva_imagen = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "        cv.imwrite('output.jpg', nueva_imagen)#probar que esta grabando\n",
    "\n",
    "        # Redimensionar la imagen\n",
    "        nueva_imagen = cv.resize(nueva_imagen, (30, 30))\n",
    "        # Aplanar la imagen\n",
    "        nueva_imagen = nueva_imagen.flatten()\n",
    "\n",
    "        # Aplicar PCA\n",
    "        lista=[]\n",
    "        lista.append(nueva_imagen)\n",
    "        image2_matrix = np.array(lista) \n",
    "#scaler = StandardScaler()\n",
    "#lista=[]\n",
    "#lista.append(image2_matrix)\n",
    "#image2_matrix = scaler.fit_transform(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar la nueva imagen utilizando los componentes especificados\n",
    "imagen_pca_reducida = transformar_imagen_pca(image2_matrix, scaler, pca_components, num_componentes, inicio_componente)\n",
    "\n",
    "imagen_pca_reducida.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction = model.predict(imagen_pca_reducida)\n",
    "\n",
    "print(\"Predicción:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
